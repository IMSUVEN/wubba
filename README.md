<h1 align="center">ğŸ§ª Wubba</h1>

<p align="center">
  <strong>Web Understanding By Behavioral Augmentation</strong><br>
  <sub>Self-supervised representation learning for HTML documents</sub>
</p>

<p align="center">
  English | <a href="./README.zh-CN.md">ç®€ä½“ä¸­æ–‡</a>
</p>

<p align="center">
  <a href="#-installation">Installation</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-features">Features</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-license">License</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.10+-3776ab?logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.7+-ee4c2c?logo=pytorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/Lightning-2.5+-792ee5?logo=lightning&logoColor=white" alt="Lightning">
  <img src="https://img.shields.io/badge/code%20style-ruff-000000?logo=ruff&logoColor=white" alt="Ruff">
  <img src="https://img.shields.io/badge/types-pyright-blue?logo=python&logoColor=white" alt="Pyright">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License">
</p>

---

Wubba learns **layout-invariant embeddings** from raw HTML using contrastive learning. Convert any HTML document into a fixed-size vector for similarity search, clustering, or classification.

```python
from wubba import WubbaInference

model = WubbaInference("model.ckpt")
embeddings = model.predict(["<html>...</html>", "<html>...</html>"])
similarity = model.compute_similarity(html1, html2)
```

## ğŸ“¦ Installation

```bash
uv sync                # or: pip install .
uv sync --group dev    # with dev tools
uv sync --extra onnx   # with ONNX export
```

## ğŸš€ Quick Start

### ğŸ” Generate Embeddings

```python
from wubba import WubbaInference

model = WubbaInference("models/best.ckpt")

# Full embeddings
embeddings = model.predict(html_docs)  # (N, 256)

# Matryoshka: truncate for speed/size tradeoff
embeddings = model.predict(html_docs, dim=64)  # (N, 64)
```

### ğŸ¯ Train a Model

```python
from wubba import Config, train

config = Config(
    data_dir="data/",
    num_epochs=100,
    batch_size=1024,
    loss_type="enhanced_hybrid",
)

model, trainer = train(config)
```

### ğŸš¢ Deploy

```python
model = WubbaInference("model.ckpt")
model.quantize()                    # INT8 for faster CPU inference
model.export_onnx("model.onnx")     # Cross-platform deployment
```

## âœ¨ Features

| Category | Features |
|----------|----------|
| âš¡ **Performance** | Flash Attention (SDPA), `torch.compile()`, INT8 quantization, ONNX export |
| ğŸ§  **Architecture** | Hierarchical RoPE, Grouped Query Attention, Relative Position Bias, RMSNorm + SwiGLU |
| ğŸ¯ **Embeddings** | Matryoshka (32/64/128/256 dims), layout-invariant representations |
| ğŸ“‰ **Loss Functions** | VICReg, InfoNCE, Spectral Contrastive, Hard Negative Mining, Alignment-Uniformity |
| ğŸ“ **Training** | Curriculum Learning, Self-Paced Learning, EMA, Collapse Detection |
| ğŸ”§ **Multi-task** | Masked Node Prediction, Structure Prediction (depth & count) |
| ğŸŒ³ **Augmentation** | Contextual (node-type specific), Tree Mixup, Semantic Replace, Subtree Shuffle |

## ğŸ—ï¸ Architecture

```
HTML â†’ Parser â†’ Node Features â†’ Transformer Encoder â†’ CLS Pooling â†’ Embedding
                     â†‘                    â†‘
              10/15 dims          Hierarchical RoPE
                                  Flash Attention
                                  RMSNorm + SwiGLU
```

ğŸ“Š **Input features per node:** tag_id, semantic_group, depth, position, num_children, sibling_count, is_leaf, parent_tag_id, tag_role, subtree_depth

## âš™ï¸ Configuration

Key options in `Config`:

```python
Config(
    # ğŸ§  Model
    transformer_dim=256,
    transformer_layers=6,
    matryoshka_dims=[32, 64, 128, 256],
    
    # ğŸ¯ Training
    loss_type="enhanced_hybrid",  # vicreg | infonce | hybrid | matryoshka_hybrid
    use_ema=True,
    enable_multitask=True,
    
    # ğŸ“Š Data
    use_extended_features=True,   # 15-dim features
    use_contextual_aug=True,
)
```

## ğŸ“š Examples

| Example | Description |
|---------|-------------|
| [01_quickstart.py](examples/01_quickstart.py) | Train and generate embeddings in minutes |
| [02_web_deduplication.py](examples/02_web_deduplication.py) | Detect duplicate/similar pages for crawlers |
| [03_similarity_search.py](examples/03_similarity_search.py) | Build a search index for HTML documents |
| [04_page_classification.py](examples/04_page_classification.py) | Classify pages using embeddings as features |
| [05_production_deployment.py](examples/05_production_deployment.py) | Quantization and ONNX export |
| [06_embedding_analysis.py](examples/06_embedding_analysis.py) | Analyze embedding quality and visualize |
| [07_custom_training.py](examples/07_custom_training.py) | Advanced training with custom callbacks |
| [08_batch_processing.py](examples/08_batch_processing.py) | Process millions of HTML documents |

## ğŸ“ Project Structure

```
src/wubba/
â”œâ”€â”€ config.py      # All hyperparameters
â”œâ”€â”€ model.py       # Encoder and loss functions
â”œâ”€â”€ data.py        # Data processing and augmentation
â”œâ”€â”€ train.py       # Training pipeline
â”œâ”€â”€ inference.py   # Inference and export
â”œâ”€â”€ metrics.py     # Embedding quality metrics
â””â”€â”€ utils.py       # DOM utilities
```

## ğŸ› ï¸ Development

```bash
uv run ruff format src    # ğŸ¨ Format
uv run ruff check src     # ğŸ” Lint
uv run pyright            # ğŸ“ Type check
```

ğŸ“– See [AGENTS.md](AGENTS.md) for detailed development guidelines.

## ğŸ“„ License

MIT